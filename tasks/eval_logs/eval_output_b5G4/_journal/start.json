{
  "version": 2,
  "eval": {
    "eval_id": "UsZtKwD7tGrkvkMviQXRZP",
    "run_id": "EB3mFk974R4JvybPJgCP38",
    "created": "2025-06-14T12:00:29-04:00",
    "task": "oldbench_eval",
    "task_id": "b5G4V3ymhC27acePkmyWjT",
    "task_version": 0,
    "task_file": "oldgov_bench.py",
    "task_registry_name": "oldbench_eval",
    "task_attribs": {},
    "task_args": {},
    "task_args_passed": {},
    "dataset": {
      "samples": 9,
      "sample_ids": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9
      ],
      "shuffled": false
    },
    "model": "openai/gpt-4o",
    "model_generate_config": {},
    "model_args": {},
    "config": {
      "epochs": 1,
      "epochs_reducer": [
        "mean"
      ],
      "fail_on_error": true,
      "sandbox_cleanup": true,
      "log_samples": true,
      "log_realtime": true,
      "log_images": true,
      "score_display": true
    },
    "packages": {
      "inspect_ai": "0.3.104"
    },
    "scorers": [
      {
        "name": "model_graded_fact",
        "options": {
          "model": "openai/gpt-4o-mini"
        },
        "metrics": [
          {
            "name": "inspect_ai/accuracy",
            "options": {}
          },
          {
            "name": "inspect_ai/stderr",
            "options": {}
          }
        ],
        "metadata": {}
      }
    ]
  },
  "plan": {
    "name": "plan",
    "steps": [
      {
        "solver": "system_message",
        "params": {
          "template": "You are an AI assistant designed to assist with answering Department of Defense policy and operations questions.\n\n## Response instructions\nPlease answer questions factually and provide a clear answer alongside relevant reasoning. If you're not sure, please say so â€” do not try to make up an answer.\n"
        }
      },
      {
        "solver": "generate",
        "params": {
          "kwargs": {
            "max_tokens": 500
          }
        }
      }
    ],
    "config": {}
  }
}